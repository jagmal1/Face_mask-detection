# -*- coding: utf-8 -*-
"""face-helmet
-detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1arocqzFUssvYgEKVafItOUXWTMpQrTUU
"""

!pip install -q kaggle

from google.colab import files
files.upload()

#creating a kagggle folder
!mkdir ~/.kaggle

#copy the kaggle.json to folder created
!cp kaggle.json ~/.kaggle/

#permission for json to act
! chmod 600 ~/.kaggle/kaggle.json

#APT fatch & unzip
!kaggle datasets download -d omkargurav/helmet-dataset -p /content/helmet_dataset --unzip

#creatint a list that contain
import os

dataset_path = "/content/helmet_dataset"
print("Files in dataset folder:", os.listdir(dataset_path))

!ls

# list with helmet

filenames_with_helmet= os.listdir('/content/helmet_dataset/data/with_helmet')
print(filenames_with_helmet)

#list without helmet

filenames_without_helmet = os.listdir("/content/helmet_dataset/data/without_helmet")
print(filenames_without_helmet)

#counting no of file in each directory
no_of_with_helmet=len(filenames_with_helmet)
no_of_without_helmet=len(filenames_without_helmet)
print('Number of images with helmet', no_of_with_helmet)
print('Number of images without helmet', no_of_without_helmet)

"""Importing the dependencies

"""

import numpy as np
from PIL import Image #importing image from pillow library
import matplotlib.image as mpimg  # used for ploting graphs
import matplotlib.pyplot as plt
import sklearn
#from sklearn.modern_selection import train_test_split

from sklearn import model_selection

#!pip install -U scikit-learn

from sklearn.model_selection import train_test_split

"""Creating labels for two class of images"""

with_helmet
_labels=[1]*3725
print(with_helmet
    _labels)

len(with_helmet
    _labels)

without_helmet
_labels=[0]*3828
print(without_helmet_labels)
len(without_helmet_labels)

labels = with_helmet_labels + without_helmet_labels
print(labels)

print(len(labels))

"""1 for with helmet


0 for without helmet


Understanding the image **dataset**
"""

# displaying the images with wearing helmet
s
img=mpimg.imread('/content/face_helmet_dataset/data/with_helmet/with_helmet
    _1007.jpg')
plt.imshow(img)

# displaying the images without wearing helmet
s
img=mpimg.imread('/content/face_helmet
    _dataset/data/without_helmet/without_helmet
    _1007.jpg')
plt.imshow(img)

"""** Now making images in one dimension

Resizinf all images and saving these image sin different folders
"""

# creating empty directories for resized images
os.mkdir('with_helmet
    _resized') # mkdir for making directories
os.mkdir('without_helmet
    _resized')

# #resized with helmet
 images

# with_helmet
_folder = '/content/face_helmet
_dataset/data/with_helmet
/'
# with_helmet
_resized_folder = '/content/with_helmet
_resized/'

# for filename in os.listdir(with_helmet
    _folder):

#   img_path = with_helmet
_folder+filename
#   img = Image.open(img_path)
#   img = img.resize((128,128))
#   img = img.convert('RGB')

# newImgPath = with_helmet
_resized_folder+filename
# img.save(newImgPath)

#resized with helmet
 images

with_helmet
_folder ='/content/face_helmet
_dataset/data/with_helmet
/'
with_helmet
_resized_folder='/content/with_helmet
_resized/'

for filename in os.listdir(with_helmet
    _folder):

  img_path = with_helmet
  _folder+filename
  img = Image.open(img_path)

  img = img.resize((128,128))   # Image.Resampling.LANCZOS
  img = img.convert('RGB')

  newImgPath = with_helmet
  _resized_folder+filename
  img.save(newImgPath)

#resized without helmet
 images

without_helmet
_folder ='/content/face_helmet
_dataset/data/without_helmet
/'
without_helmet
_resized_folder='/content/without_helmet
_resized/'

for filename in os.listdir(without_helmet
    _folder):

  img_path = without_helmet
  _folder+filename
  img = Image.open(img_path)

  img = img.resize((128,128))
  img = img.convert('RGB')

  newImgPath = without_helmet
  _resized_folder+filename
  img.save(newImgPath)

"""Resized Images"""

img=mpimg.imread('/content/without_helmet
    _resized/without_helmet
    _1007.jpg')
plt.imshow(img)

img=mpimg.imread('/content/with_helmet
    _resized/with_helmet
    _1007.jpg')
plt.imshow(img)

"""**Converting image to numpy array**"""

import cv2
import glob #library for image recognition

#reading with helmet
 images
imdir='/content/with_helmet
_resized/'
#imlist=glob.glob(imdir+'*.jpg')
ext=['jpg','png']
files=[]
[files.extend(glob.glob(imdir+'*.' + e)) for e in ext]

with_helmet
_images = np.asarray([cv2.imread(file) for file in files])

#reading without helmet
 images
imdir='/content/without_helmet
_resized/'

ext=['jpg','png']
files=[]
[files.extend(glob.glob(imdir+'*.' + e)) for e in ext]

without_helmet
_images = np.asarray([cv2.imread(file) for file in files])

print(with_helmet
    _images)

print(without_helmet
    _images)

print(with_helmet
    _images.shape)
print(without_helmet
    _images.shape)

combined_images=np.concatenate((with_helmet
    _images,without_helmet
    _images))
print(combined_images.shape)

from re import X
#data & labels
X=combined_images
Y=np.asarray(labels)

"""Spliting Taining data & Test data"""

X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)

print(X.shape,X_train.shape,X_test.shape,Y_train.shape,Y_test.shape)

#Normalizing/Standardizing the data

X_train_sd = X_train/255
Y_train_sd = Y_train/255
X_test_sd = X_test/255
Y_test_sd = Y_test/25

print(X_train_sd)

print(X_train_sd[0])

"""Building the Neural Netwaork"""

import tensorflow as tf
import keras

model = keras.Sequential([

                          keras.layers.Flatten(input_shape=(128,128,3)),
                          keras.layers.Dense(128,activation='relu'),
                          keras.layers.Dense(128,activation='relu'),
                          keras.layers.Dense(128,activation='relu'),
                          keras.layers.Dense(2,activation='softmax')
])

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(X_train_sd,Y_train,epochs=30)

score,acc=model.evaluate(X_test_sd,Y_test)
print('Test data loss:',score)
print('Test accuracy:',acc)

"""Building a Predictive System"""

from google.colab.patches import cv2_imshow # imshow does not work with google.colab so we import cv2_imshow

imput_image_path = input('Path of the image to be predictec:')
imput_image = cv2.imread(imput_image_path)
cv2_imshow(imput_image)

input_image_resized = cv2.resize(imput_image,(128,128))
input_image_scaled = input_image_resized/255

input_image_reshaped = np.reshape(input_image_scaled,[1,128,128,3])

input_prediction = model.predict(input_image_reshaped)

input_pred_label = np.argmax(input_prediction)

if input_pred_label == 1:
  print('The person is wearing helmet
  ')
else:
  print('The person is not wearing helmet
  ')

imput_image_path = input('Path of the image to be predictec:')
imput_image = cv2.imread(imput_image_path)
cv2_imshow(imput_image)

input_image_resized = cv2.resize(imput_image,(128,128))
input_image_scaled = input_image_resized/255

input_image_reshaped = np.reshape(input_image_scaled,[1,128,128,3])

input_prediction = model.predict(input_image_reshaped)

input_pred_label = np.argmax(input_prediction)

if input_pred_label == 1:
  print('The person is wearing helmet
  ')
else:
  print('The person is not wearing helmet
  ')
